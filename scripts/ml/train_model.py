import sys
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import MinMaxScaler
import joblib
import json
from datetime import datetime
from pathlib import Path

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

class StockPredictionTrainer:
    def __init__(self, data_dir='./data', model_dir='./models'):
        self.data_dir = Path(data_dir)
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        self.scaler = MinMaxScaler()

    def load_data(self, stock_code: str = None):
        """ë°ì´í„° ë¡œë“œ"""
        if stock_code:
            # íŠ¹ì • ì¢…ëª©
            df = pd.read_csv(f'{self.data_dir}/processed/{stock_code}_features.csv')
        else:
            # ì „ì²´ ì¢…ëª©
            df = pd.read_csv(f'{self.data_dir}/datasets/train.csv')
        return df

    def create_features(self, df: pd.DataFrame):
        """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
        # ê¸°ìˆ ì  ì§€í‘œ
        df['ma5'] = df['close'].rolling(window=5).mean()
        df['ma10'] = df['close'].rolling(window=10).mean()
        df['ma20'] = df['close'].rolling(window=20).mean()

        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))

        # ë³¼ë¦°ì € ë°´ë“œ
        df['bb_middle'] = df['close'].rolling(window=20).mean()
        df['bb_std'] = df['close'].rolling(window=20).std()
        df['bb_upper'] = df['bb_middle'] + (df['bb_std'] * 2)
        df['bb_lower'] = df['bb_middle'] - (df['bb_std'] * 2)

        # ê°€ê²© ë³€í™”ìœ¨
        df['price_change'] = df['close'].pct_change()
        df['volume_change'] = df['volume'].pct_change()

        # íƒ€ê²Ÿ: ë‹¤ìŒë‚  ì¢…ê°€
        df['target'] = df['close'].shift(-1)

        # NaN ì œê±°
        df = df.dropna()

        return df

    def train(self, stock_code: str = None):
        """ëª¨ë¸ í•™ìŠµ"""
        print(f"\n{'='*50}")
        print(f"ðŸš€ Starting model training...")
        print(f"{'='*50}\n")

        # 1. ë°ì´í„° ë¡œë“œ
        df = self.load_data(stock_code)
        print(f"ðŸ“Š Loaded data: {len(df)} records")

        if len(df) == 0:
            raise ValueError("No data to train on. Please run preprocess_data.py first.")

        # 2. í”¼ì²˜/íƒ€ê²Ÿ ë¶„ë¦¬ (ì „ì²˜ë¦¬ëœ ë°ì´í„°ì—ëŠ” ì´ë¯¸ í”¼ì²˜ê°€ ìžˆìŒ)
        feature_columns = ['open', 'high', 'low', 'close', 'volume',
                          'ma5', 'ma10', 'ma20', 'rsi',
                          'bb_upper', 'bb_middle', 'bb_lower',
                          'macd', 'macd_signal', 'macd_diff',
                          'price_change_1d', 'volume_change']

        # ë°ì´í„°ì— ì‹¤ì œ ì¡´ìž¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        available_features = [col for col in feature_columns if col in df.columns]
        print(f"ðŸ“ˆ Using {len(available_features)} features: {', '.join(available_features[:5])}...")

        X = df[available_features]
        y = df['target_price']  # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ìƒì„±ëœ íƒ€ê²Ÿ ë³€ìˆ˜

        # 3. ë°ì´í„° ë¶„í• 
        print(f"âœ‚ï¸  Splitting data: 80% train, 20% test...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, shuffle=False  # ì‹œê³„ì—´ì€ shuffle=False
        )
        print(f"   Train set: {len(X_train)} samples")
        print(f"   Test set: {len(X_test)} samples\n")

        # 4. ìŠ¤ì¼€ì¼ë§
        print(f"âš™ï¸  Scaling features...")
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # 5. ëª¨ë¸ í•™ìŠµ
        print(f"ðŸŽ¯ Training GradientBoostingRegressor...")
        model = GradientBoostingRegressor(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=5,
            random_state=42
        )
        model.fit(X_train_scaled, y_train)
        print(f"âœ… Training completed!\n")

        # 6. í‰ê°€
        train_score = model.score(X_train_scaled, y_train)
        test_score = model.score(X_test_scaled, y_test)

        print(f"ðŸ“Š Model Performance:")
        print(f"   Train RÂ² Score: {train_score:.4f}")
        print(f"   Test RÂ² Score: {test_score:.4f}\n")

        # 7. ëª¨ë¸ ì €ìž¥
        model_name = f'{stock_code}_model.pkl' if stock_code else 'stock_prediction_v1.pkl'
        model_path = self.model_dir / model_name
        scaler_path = self.model_dir / 'scaler.pkl'

        print(f"ðŸ’¾ Saving model...")
        joblib.dump(model, model_path)
        joblib.dump(self.scaler, scaler_path)
        print(f"   Model: {model_path}")
        print(f"   Scaler: {scaler_path}\n")

        # 8. ë©”íƒ€ë°ì´í„° ì €ìž¥
        metadata = {
            'model_name': model_name,
            'stock_code': stock_code,
            'trained_at': datetime.now().isoformat(),
            'train_score': float(train_score),
            'test_score': float(test_score),
            'n_samples': len(df),
            'feature_columns': available_features
        }

        metadata_path = self.model_dir / 'metadata.json'
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"ðŸ“„ Metadata saved: {metadata_path}\n")

        print(f"{'='*50}")
        print(f"âœ… Model training completed successfully!")
        print(f"{'='*50}\n")

        return model, metadata

# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == '__main__':
    trainer = StockPredictionTrainer()

    # ì „ì²´ ì¢…ëª© í•™ìŠµ
    model, metadata = trainer.train()

    # íŠ¹ì • ì¢…ëª© í•™ìŠµ (ì„ íƒ)
    # model, metadata = trainer.train('005930')